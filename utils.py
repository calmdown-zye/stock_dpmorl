from collections import OrderedDict
from copy import deepcopy
from typing import Any, Callable, List, Optional, Sequence, Type, Union

import gym
import numpy as np

from stable_baselines3.common.vec_env.base_vec_env import (
    VecEnv,
    VecEnvIndices,
    VecEnvObs,
    VecEnvStepReturn,
)

# SB3 ë²„ì „ í˜¸í™˜ìš©: dict_to_obs, obs_space_info ìœ„ì¹˜ê°€ ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„
try:
    from stable_baselines3.common.vec_env.util import dict_to_obs, obs_space_info
except ImportError:
    from stable_baselines3.common.vec_env.utils import dict_to_obs, obs_space_info

# gym â†’ gymnasium í˜¸í™˜ ëž˜í¼
from stable_baselines3.common.vec_env.patch_gym import _patch_env


def copy_obs_dict(obs):
    """
    ì˜ˆì „ SB3 util.py ì— ìžˆë˜ copy_obs_dict ë¥¼ ì—¬ê¸°ì„œ ì§ì ‘ ì •ì˜.

    obs: dict(str -> np.ndarray) í˜¹ì€ np.ndarray
    ë°˜í™˜: ê°’ë“¤ì´ np.copy ëœ ìƒˆ ê°ì²´
    """
    if isinstance(obs, dict):
        return {k: np.copy(v) for k, v in obs.items()}
    else:
        return np.copy(obs)


class DummyVecEnv(VecEnv):
    """
    Creates a simple vectorized wrapper for multiple environments, calling each environment in sequence on the current
    Python process. This is useful for computationally simple environment such as ``cartpole-v1``,
    as the overhead of multiprocess or multithread outweighs the environment computation time.
    This can also be used for RL methods that
    require a vectorized environment, but that you want a single environments to train with.

    :param env_fns: a list of functions
        that return environments to vectorize
    :raises ValueError: If the same environment instance is passed as the output of two or more different env_fn.
    """

    def __init__(self, env_fns: List[Callable[[], gym.Env]], reward_dim: int = 2):
        # 1) ì›ëž˜ gym.Env ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ë¨¼ì € ìƒì„±
        raw_envs = [fn() for fn in env_fns]

        # 2) SB3ì—ì„œ ì œê³µí•˜ëŠ” gym â†’ gymnasium í˜¸í™˜ ëž˜í¼ ì ìš©
        #    ì´ë ‡ê²Œ í•´ì•¼ action_space / observation_space ê°€ gymnasium.spaces.* íƒ€ìž…ìœ¼ë¡œ ë³€í™˜ë¨
        self.envs = [_patch_env(env) for env in raw_envs]

        # 3) ê°™ì€ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìž¬ì‚¬ìš©í–ˆëŠ”ì§€ ì²´í¬
        if len(set([id(env.unwrapped) for env in self.envs])) != len(self.envs):
            raise ValueError(
                "You tried to create multiple environments, but the function to create them returned the same instance "
                "instead of creating different objects. "
                "You are probably using `make_vec_env(lambda: env)` or `DummyVecEnv([lambda: env] * n_envs)`. "
                "You should replace `lambda: env` by a `make_env` function that "
                "creates a new instance of the environment at every call "
                "(using `gym.make()` for instance). You can take a look at the documentation for an example. "
                "Please read https://github.com/DLR-RM/stable-baselines3/issues/1151 for more information."
            )

        # 4) VecEnv ì´ˆê¸°í™” (ì—¬ê¸°ì„œ env.observation_space / env.action_space ëŠ” ì´ë¯¸ gymnasium.spaces.*)
        env = self.envs[0]
        VecEnv.__init__(self, len(env_fns), env.observation_space, env.action_space)

        obs_space = env.observation_space
        self.keys, shapes, dtypes = obs_space_info(obs_space)

        self.buf_obs = OrderedDict(
            [
                (k, np.zeros((self.num_envs, *tuple(shapes[k])), dtype=dtypes[k]))
                for k in self.keys
            ]
        )
        self.buf_dones = np.zeros((self.num_envs,), dtype=bool)
        self.buf_rews = np.zeros((self.num_envs, reward_dim), dtype=np.float32)
        self.buf_infos = [{} for _ in range(self.num_envs)]
        self.actions = None
        self.metadata = env.metadata
        # ðŸ”¥ ì—¬ê¸° ì¶”ê°€: ì—í”¼ì†Œë“œ ëˆ„ì  ë²„í¼
        self.reward_dim = reward_dim
        self.ep_rets = np.zeros((self.num_envs, reward_dim), dtype=np.float32)
        self.ep_lens = np.zeros(self.num_envs, dtype=int)

    def step_async(self, actions: np.ndarray) -> None:
        self.actions = actions

    def step_wait(self) -> VecEnvStepReturn:
        """
        Gym / Gymnasium í˜¼ìš© ëŒ€ì‘ + ì—í”¼ì†Œë“œ ë¦¬í„´ ëˆ„ì :
        - env.step(action)ì´ 4ê°œ (obs, reward, done, info)ë¥¼ ì¤„ ìˆ˜ë„ ìžˆê³ 
        - 5ê°œ (obs, reward, terminated, truncated, info)ë¥¼ ì¤„ ìˆ˜ë„ ìžˆìŒ.

        ë‚´ë¶€ì ìœ¼ë¡œëŠ” í•­ìƒ:
            obs, reward_vec, done, info
        í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”í•´ì„œ ë²„í¼ì— ìŒ“ê³ ,
        done=Trueì¼ ë•Œ info["episode"]["r"]ì— ì—í”¼ì†Œë“œ ëˆ„ì  ë³´ìƒì„ ë„£ì–´ì¤€ë‹¤.
        """
        for env_idx in range(self.num_envs):
            step_result = self.envs[env_idx].step(self.actions[env_idx])

            # 5-return (Gymnasium ìŠ¤íƒ€ì¼)
            if isinstance(step_result, (tuple, list)) and len(step_result) == 5:
                obs, rew, terminated, truncated, info = step_result
                done = bool(terminated or truncated)
            # 4-return (ì˜› Gym ìŠ¤íƒ€ì¼)
            elif isinstance(step_result, (tuple, list)) and len(step_result) == 4:
                obs, rew, done, info = step_result
            else:
                raise RuntimeError(
                    f"DummyVecEnv.step_wait: ì˜ˆìƒì¹˜ ëª»í•œ step ë°˜í™˜ê°’: "
                    f"type={type(step_result)}, len={len(step_result) if hasattr(step_result, '__len__') else 'N/A'}"
                )

            # --- ë³´ìƒ ë²„í¼ ì—…ë°ì´íŠ¸ ---
            rew_arr = np.asarray(rew, dtype=np.float32).reshape(-1)
            self.buf_rews[env_idx] = rew_arr
            self.buf_dones[env_idx] = bool(done)

            # --- ì—í”¼ì†Œë“œ ëˆ„ì  (vector reward ê¸°ì¤€) ---
            self.ep_rets[env_idx] += rew_arr
            self.ep_lens[env_idx] += 1

            info = dict(info)  # ìˆ˜ì • ê°€ëŠ¥í•˜ë„ë¡ ë³µì‚¬

            if done:
                # ì´ë²ˆ ì—í”¼ì†Œë“œì˜ ëˆ„ì  ë²¡í„° ë¦¬í„´ì„ info["episode"]["r"]ì— ì €ìž¥
                info["episode"] = {
                    "r": self.ep_rets[env_idx].copy(),       # shape = (reward_dim,)
                    "l": int(self.ep_lens[env_idx]),         # ì—í”¼ì†Œë“œ ê¸¸ì´
                }

                # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì¤€ë¹„
                self.ep_rets[env_idx][:] = 0.0
                self.ep_lens[env_idx] = 0

                # terminal obs ì €ìž¥ í›„ reset
                info["terminal_observation"] = obs
                obs = self.envs[env_idx].reset()

            self.buf_infos[env_idx] = info
            self._save_obs(env_idx, obs)

        return (
            self._obs_from_buf(),
            np.copy(self.buf_rews),
            np.copy(self.buf_dones),
            deepcopy(self.buf_infos),
        )



    def seed(self, seed: Optional[int] = None) -> List[Union[None, int]]:
        if seed is None:
            seed = np.random.randint(0, 2**32 - 1)
        seeds = []
        for idx, env in enumerate(self.envs):
            seeds.append(env.seed(seed + idx))
        return seeds

    def reset(self) -> VecEnvObs:
        for env_idx in range(self.num_envs):
            obs = self.envs[env_idx].reset()
            self._save_obs(env_idx, obs)
        return self._obs_from_buf()

    def close(self) -> None:
        for env in self.envs:
            env.close()

    def get_images(self) -> Sequence[np.ndarray]:
        return [env.render(mode="rgb_array") for env in self.envs]

    def render(self, mode: str = "human") -> Optional[np.ndarray]:
        """
        Gym environment rendering. If there are multiple environments then
        they are tiled together in one image via ``BaseVecEnv.render()``.
        Otherwise (if ``self.num_envs == 1``), we pass the render call directly to the
        underlying environment.
        """
        if self.num_envs == 1:
            return self.envs[0].render(mode=mode)
        else:
            return super().render(mode=mode)

    def _save_obs(self, env_idx: int, obs: VecEnvObs) -> None:
        """
        obs ê°€ np.ndarray, dict, list, tuple ë“± ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ
        SB3/VecEnv ë²„í¼ êµ¬ì¡°ì— ë§žê²Œ ë³€í™˜í•œë‹¤.
        """
        # (obs, info) íŠœí”Œë¡œ ì˜¤ëŠ” ê²½ìš° -> obsë§Œ ì·¨í•¨
        if isinstance(obs, (list, tuple)):
            if len(obs) > 0:
                obs = obs[0]

        # dict í˜•íƒœë©´ keyë³„ë¡œ ì €ìž¥
        if isinstance(obs, dict):
            for key in self.keys:
                v = np.asarray(obs[key], dtype=np.float32)
                self.buf_obs[key][env_idx] = np.nan_to_num(v)
        else:
            # ndarray í˜•íƒœë¡œ ê°•ì œ ë³€í™˜
            arr = np.asarray(obs, dtype=np.float32)

            # í˜¹ì‹œ ì°¨ì›ì´ ë§žì§€ ì•Šìœ¼ë©´ flatten
            if arr.ndim > 1:
                arr = arr.flatten()

            key = self.keys[0]
            self.buf_obs[key][env_idx] = np.nan_to_num(arr)



    def _obs_from_buf(self) -> VecEnvObs:
        return dict_to_obs(self.observation_space, copy_obs_dict(self.buf_obs))

    def get_attr(self, attr_name: str, indices: VecEnvIndices = None) -> List[Any]:
        """Return attribute from vectorized environment (see base class)."""
        target_envs = self._get_target_envs(indices)
        return [getattr(env_i, attr_name) for env_i in target_envs]

    def set_attr(self, attr_name: str, value: Any, indices: VecEnvIndices = None) -> None:
        """Set attribute inside vectorized environments (see base class)."""
        target_envs = self._get_target_envs(indices)
        for env_i in target_envs:
            setattr(env_i, attr_name, value)

    def env_method(
        self,
        method_name: str,
        *method_args,
        indices: VecEnvIndices = None,
        **method_kwargs,
    ) -> List[Any]:
        """Call instance methods of vectorized environments."""
        target_envs = self._get_target_envs(indices)
        return [
            getattr(env_i, method_name)(*method_args, **method_kwargs)
            for env_i in target_envs
        ]

    def env_is_wrapped(
        self,
        wrapper_class: Type[gym.Wrapper],
        indices: VecEnvIndices = None,
    ) -> List[bool]:
        """Check if worker environments are wrapped with a given wrapper"""
        target_envs = self._get_target_envs(indices)
        from stable_baselines3.common import env_util  # avoid circular import

        return [env_util.is_wrapped(env_i, wrapper_class) for env_i in target_envs]

    def _get_target_envs(self, indices: VecEnvIndices) -> List[gym.Env]:
        indices = self._get_indices(indices)
        return [self.envs[i] for i in indices]
