import os
import time
import random
import logging
from datetime import datetime, timedelta

import numpy as np
import pandas as pd
import requests
import yfinance as yf
from yahooquery import Ticker
import pandas_datareader.data as web

# --- ë¡œê±° ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# --- ìƒìˆ˜ ì„¤ì • ---
USER_AGENTS = [
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
]
CACHE_DIR = "data/cache"
os.makedirs(CACHE_DIR, exist_ok=True)

# --- ë„ìš°ë¯¸ í•¨ìˆ˜ ---

def _clean(df: pd.DataFrame) -> pd.DataFrame:
    """DataFrameì˜ ë¬´í•œëŒ€ ê°’ì„ NaNìœ¼ë¡œ ë°”ê¾¸ê³ , ëª¨ë“  ê°’ì´ NaNì¸ ì¹¼ëŸ¼ì„ ì œê±°í•©ë‹ˆë‹¤."""
    if df is None or df.empty:
        return pd.DataFrame()
    df = df.replace([np.inf, -np.inf], np.nan)
    df = df.dropna(axis=1, how='all')
    return df

def _tag(tickers: list[str], years: int) -> str:
    """ìºì‹œ íŒŒì¼ëª…ì„ ìœ„í•œ ê³ ìœ  íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return f"{'-'.join(sorted(tickers))}_{years}y"

def _save_cache(df: pd.DataFrame, tag: str):
    """DataFrameì„ Parquet í˜•ì‹ìœ¼ë¡œ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
    path = os.path.join(CACHE_DIR, f"close_{tag}.parquet")
    try:
        df.to_parquet(path)
        logging.info(f"âœ… Cache saved successfully to {path}")
    except Exception as e:
        logging.error(f"Failed to save cache to {path}: {e}")

def _load_cache(tag: str) -> pd.DataFrame:
    """ìºì‹œì—ì„œ Parquet íŒŒì¼ì„ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    path = os.path.join(CACHE_DIR, f"close_{tag}.parquet")
    if os.path.exists(path):
        try:
            logging.info(f"ğŸ’¾ Loading data from cache: {path}")
            return pd.read_parquet(path)
        except Exception as e:
            logging.warning(f"Could not read cache file {path}, attempting to re-download. Error: {e}")
    return pd.DataFrame()

# --- ë°ì´í„° ì†ŒìŠ¤ë³„ ë‹¤ìš´ë¡œë” í•¨ìˆ˜ ---

def _yf_download_chunked(tickers: list[str], start: str, end: str, **kwargs) -> pd.DataFrame:
    """yfinanceë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë¶„í•  ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤. (HTTP 429 ì˜¤ë¥˜ ì™„í™”)"""
    chunk_size = kwargs.get('chunk_size', 5)
    pause = kwargs.get('pause', 1.5)
    max_retry = kwargs.get('max_retry', 3)
    
    all_closes = []
    for i in range(0, len(tickers), chunk_size):
        chunk = tickers[i:i + chunk_size]
        for attempt in range(max_retry):
            try:
                session = requests.Session()
                session.headers.update({"User-Agent": random.choice(USER_AGENTS)})
                
                raw = yf.download(
                    chunk, start=start, end=end,
                    auto_adjust=True, progress=False, threads=False, session=session
                )
                
                if raw.empty:
                    logging.warning(f"No data for tickers {chunk} in this period.")
                    break # ì„±ê³µì ìœ¼ë¡œ ë¹„ì–´ìˆëŠ” ë°ì´í„°ë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ ì¬ì‹œë„ ë¶ˆí•„ìš”

                # yfinanceëŠ” í‹°ì»¤ê°€ í•˜ë‚˜ì¼ ë•Œì™€ ì—¬ëŸ¬ ê°œì¼ ë•Œ ë‹¤ë¥¸ êµ¬ì¡°ì˜ DataFrameì„ ë°˜í™˜
                if isinstance(raw.columns, pd.MultiIndex):
                    close = raw.get('Close', pd.DataFrame())
                else:
                    close = raw[['Close']].rename(columns={'Close': chunk[0]}) if 'Close' in raw else pd.DataFrame()
                
                all_closes.append(close)
                time.sleep(pause)
                break # ì²­í¬ ì„±ê³µ, ë‹¤ìŒ ì²­í¬ë¡œ ì´ë™
            except Exception as e:
                logging.warning(f"Attempt {attempt+1}/{max_retry} failed for chunk {chunk}: {e}")
                if attempt + 1 == max_retry:
                    logging.error(f"ğŸš¨ Failed to download chunk {chunk} after {max_retry} retries. Aborting yfinance download.")
                    return pd.DataFrame() # í•œ ì²­í¬ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì „ì²´ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì²˜ë¦¬
                time.sleep(pause * (attempt + 2)) # ì ì§„ì  ë°±ì˜¤í”„

    if not all_closes:
        return pd.DataFrame()
        
    final_df = pd.concat(all_closes, axis=1)
    return _clean(final_df).sort_index()

def _yahooquery_download(tickers: list[str], years: int, **kwargs) -> pd.DataFrame:
    """yahooqueryë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        t = Ticker(tickers, asynchronous=True, formatted=True)
        hist = t.history(period=f"{years}y")
        
        if not isinstance(hist, dict): # yahooquery v2.3+
            close = hist.get('close', pd.DataFrame()).unstack(level=0)
        else: # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
             close = pd.DataFrame({k: v['close'] for k, v in hist.items() if 'close' in v})
        
        return _clean(close).sort_index()
    except Exception as e:
        logging.error(f"yahooquery download failed: {e}")
        return pd.DataFrame()

def _stooq_download(tickers: list[str], start: str, end: str, **kwargs) -> pd.DataFrame:
    """stooqë¥¼ í†µí•´ ë¯¸êµ­ ì£¼ì‹ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    all_closes = []
    for ticker in tickers:
        try:
            # StooqëŠ” ë¯¸êµ­ ì£¼ì‹ì— .US ì ‘ë¯¸ì‚¬ë¥¼ ë¶™ì—¬ì•¼ í•  ìˆ˜ ìˆìŒ
            symbol = f"{ticker.replace('-', '.')}.US"
            s = web.DataReader(symbol, "stooq", start, end)["Close"].rename(ticker)
            all_closes.append(s)
        except Exception:
            logging.warning(f"Could not download {ticker} from stooq.")
    
    if not all_closes:
        return pd.DataFrame()

    final_df = pd.concat(all_closes, axis=1)
    return _clean(final_df).sort_index()

# --- ë©”ì¸ í•¨ìˆ˜ ---

def download_close(tickers: list[str], years: int = 10, use_cache: bool = True) -> pd.DataFrame:
    """
    ì§€ì •ëœ í‹°ì»¤ ëª©ë¡ê³¼ ê¸°ê°„ì— ëŒ€í•œ ì¢…ê°€ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ë©°, ë¡œì»¬ ìºì‹œë¥¼ í™œìš©í•©ë‹ˆë‹¤.

    Args:
        tickers (list[str]): ë‹¤ìš´ë¡œë“œí•  ì£¼ì‹ í‹°ì»¤ ë¦¬ìŠ¤íŠ¸.
        years (int): ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ì˜ ê¸°ê°„ (ë…„).
        use_cache (bool): ë¡œì»¬ ìºì‹œ ì‚¬ìš© ì—¬ë¶€.

    Returns:
        pd.DataFrame: ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ, í‹°ì»¤ë¥¼ ì¹¼ëŸ¼ìœ¼ë¡œ í•˜ëŠ” ì¢…ê°€ ë°ì´í„°.
                       ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•˜ë©´ ë¹ˆ DataFrameì„ ë°˜í™˜.
    """
    tag = _tag(tickers, years)
    if use_cache:
        cached_df = _load_cache(tag)
        if not cached_df.empty:
            return cached_df

    logging.info(f"No cache found for tag '{tag}'. Starting download...")
    
    end = datetime.today()
    start = end - timedelta(days=365.25 * years)
    start_str, end_str = start.strftime('%Y-%m-%d'), end.strftime('%Y-%m-%d')
    
    # ì‹œë„í•  ë°ì´í„° ì†ŒìŠ¤ì™€ í•„ìš”í•œ ì¸ìë“¤ì„ ìˆœì„œëŒ€ë¡œ ì •ì˜
    data_sources = [
        ("yfinance", _yf_download_chunked, {"start": start_str, "end": end_str}),
        ("yahooquery", _yahooquery_download, {"years": years}),
        ("stooq", _stooq_download, {"start": start_str, "end": end_str}),
    ]

    final_df = pd.DataFrame()
    for name, downloader, params in data_sources:
        logging.info(f"--- Attempting to download from {name.upper()} ---")
        final_df = downloader(tickers=tickers, **params)
        
        if not final_df.empty:
            logging.info(f"âœ… Successfully downloaded data from {name.upper()}.")
            if use_cache:
                _save_cache(final_df, tag)
            return final_df
        else:
            logging.warning(f"âš ï¸ Failed to get data from {name.upper()}. Trying next source...")
            
    logging.error("ğŸš¨ All data sources failed and no cache available.")
    return pd.DataFrame()

# src/data/loader_yf.py
def load_market_frames(tickers, years=3, use_cache=True):
    close = download_close(tickers, years=years, use_cache=use_cache)

    # 1) ë‚ ì§œ ì •ë ¬ + dtype
    close = close.sort_index().astype("float32")

    # 2) ì™„ì „ê²°ì¸¡ ì¹¼ëŸ¼ ì œê±° + ì•/ë’¤ ì±„ì›€
    close = close.dropna(axis=1, how="all").ffill().bfill()

    # 3) ìˆ˜ìµë¥  + ë¶„ì‚° 0 ìì‚° ì œê±°
    ret = close.pct_change().dropna()
    keep = ret.std() > 0
    close = close.loc[ret.index, keep]
    ret   = ret.loc[:, keep]

    assert close.shape[1] > 0 and ret.shape[1] > 0, "ìì‚°ì´ 0ê°œê°€ ë¨ â€“ ë°ì´í„° ë¡œë”©/ì „ì²˜ë¦¬ í™•ì¸"
    return close, ret

def load_yf_panel(tickers, start=None, end=None, years=10, win_vol=20):
    """
    ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ìš©: (close, ret, vol) ë°˜í™˜.
    start/endë¡œ ìŠ¬ë¼ì´ìŠ¤ í›„ ì¸ë±ìŠ¤ ì •ë ¬ ë§ì¶°ì„œ ë¦¬í„´.
    """
    close, ret = load_market_frames(tickers, years=years, use_cache=True)

    if start or end:
        close = close.loc[start:end]
        # ìŠ¬ë¼ì´ìŠ¤ ì´í›„ ret ì¬ê³„ì‚°(ì¸ë±ìŠ¤ ì •í•© ë³´ì¥)
        ret = close.pct_change().dropna()
        close = close.loc[ret.index]

    vol = ret.rolling(win_vol).std().bfill()
    return close, ret, vol

def compute_base_signals(close: pd.DataFrame, ret: pd.DataFrame, win_mom: int = 20, win_vol: int = 20):
    """
    ê¸°ì¡´ import ê²½ë¡œ í˜¸í™˜ìš©. (mom, val, vol) ì‹œê·¸ë„ dict ë°˜í™˜.
    - mom: ëª¨ë©˜í…€ (win_mom ìˆ˜ìµë¥ )
    - val: ë°¸ë¥˜ proxy (1/price)
    - vol: ë³€ë™ì„± (ret std rolling win_vol)
    ì¸ë±ìŠ¤/ì»¬ëŸ¼ retì— ë§ì¶° ì •ë ¬.
    """
    # ëª¨ë©˜í…€: win_mom ê¸°ê°„ ì¢…ê°€ ë³€í™”ìœ¨
    mom = close.pct_change(win_mom).dropna()

    # ë°¸ë¥˜: 1/Close (inf/NaN ì •ë¦¬)
    val = (1.0 / close).replace([np.inf, -np.inf], np.nan).ffill()

    # ë³€ë™ì„±: ìˆ˜ìµë¥  std ë¡¤ë§
    vol = ret.rolling(win_vol).std().bfill()

    # ì¸ë±ìŠ¤/ì»¬ëŸ¼ ì •í•©(í™˜ê²½ì€ ret ê¸°ì¤€ìœ¼ë¡œ êµ´ëŸ¬ê°€ë‹ˆê¹Œ ret.indexë¡œ ë§ì¶¤)
    common_idx = ret.index.intersection(mom.index).intersection(val.index).intersection(vol.index)
    mom = mom.loc[common_idx, ret.columns].astype("float32")
    val = val.loc[common_idx, ret.columns].astype("float32")
    vol = vol.loc[common_idx, ret.columns].astype("float32")

    return {"mom": mom, "val": val, "vol": vol}


if __name__ == '__main__':
    # --- í…ŒìŠ¤íŠ¸ ì˜ˆì œ ---
    test_tickers = ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'NVDA']
    
    print("--- 1. ìºì‹œ ì—†ì´ ì²« ë‹¤ìš´ë¡œë“œ ì‹œë„ ---")
    data = download_close(tickers=test_tickers, years=1, use_cache=True)
    
    if not data.empty:
        print("\n--- ë‹¤ìš´ë¡œë“œ ì„±ê³µ! ë°ì´í„° í™•ì¸ ---")
        print(data.head())
        print(data.tail())
        
        print("\n--- 2. ìºì‹œë¥¼ ì‚¬ìš©í•´ ë‹¤ì‹œ ë¡œë“œ ì‹œë„ ---")
        # ìºì‹œì—ì„œ ë°”ë¡œ ë¡œë“œë˜ì–´ì•¼ í•˜ë¯€ë¡œ ë§¤ìš° ë¹¨ë¼ì•¼ í•¨
        cached_data = download_close(tickers=test_tickers, years=1, use_cache=True)
        print("ë¡œë“œëœ ë°ì´í„°:")
        print(cached_data.head())
    else:
        print("\n--- ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ---")